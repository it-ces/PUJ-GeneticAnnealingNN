{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from preprocessing import complete_vars\n",
    "from preprocessing import ratios\n",
    "from preprocessing import breakdown_vars\n",
    "from preprocessing import dummies_ohe\n",
    "from preprocessing import Xy\n",
    "from preprocessing import std_z\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 771 entries, 4 to 26499\n",
      "Data columns (total 12 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   Ganancia bruta                      353 non-null    float64\n",
      " 1   Ganancia (pérdida)                  353 non-null    float64\n",
      " 2   Ingresos de actividades ordinarias  353 non-null    float64\n",
      " 3   Costo de ventas                     330 non-null    float64\n",
      " 4   Patrimonio total                    353 non-null    float64\n",
      " 5   Total pasivos                       353 non-null    float64\n",
      " 6   Total de activos                    353 non-null    float64\n",
      " 7   Ganancias acumuladas                351 non-null    float64\n",
      " 8   Pasivos corrientes totales          352 non-null    float64\n",
      " 9   Activos corrientes totales          353 non-null    float64\n",
      " 10  event                               771 non-null    float64\n",
      " 11  Sector                              771 non-null    object \n",
      "dtypes: float64(11), object(1)\n",
      "memory usage: 78.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 328 entries, 4 to 14903\n",
      "Data columns (total 13 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   Ganancia bruta                      328 non-null    float64\n",
      " 1   Ganancia (pérdida)                  328 non-null    float64\n",
      " 2   Ingresos de actividades ordinarias  328 non-null    float64\n",
      " 3   Costo de ventas                     328 non-null    float64\n",
      " 4   Patrimonio total                    328 non-null    float64\n",
      " 5   Total pasivos                       328 non-null    float64\n",
      " 6   Total de activos                    328 non-null    float64\n",
      " 7   Ganancias acumuladas                328 non-null    float64\n",
      " 8   Pasivos corrientes totales          328 non-null    float64\n",
      " 9   Activos corrientes totales          328 non-null    float64\n",
      " 10  event                               328 non-null    float64\n",
      " 11  Sector                              328 non-null    object \n",
      " 12  complete-vars                       328 non-null    float64\n",
      "dtypes: float64(12), object(1)\n",
      "memory usage: 35.9+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 328 entries, 4 to 14903\n",
      "Data columns (total 23 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   Ganancia bruta                      328 non-null    float64\n",
      " 1   Ganancia (pérdida)                  328 non-null    float64\n",
      " 2   Ingresos de actividades ordinarias  328 non-null    float64\n",
      " 3   Costo de ventas                     328 non-null    float64\n",
      " 4   Patrimonio total                    328 non-null    float64\n",
      " 5   Total pasivos                       328 non-null    float64\n",
      " 6   Total de activos                    328 non-null    float64\n",
      " 7   Ganancias acumuladas                328 non-null    float64\n",
      " 8   Pasivos corrientes totales          328 non-null    float64\n",
      " 9   Activos corrientes totales          328 non-null    float64\n",
      " 10  event                               328 non-null    float64\n",
      " 11  Sector                              328 non-null    object \n",
      " 12  complete-vars                       328 non-null    float64\n",
      " 13  DER                                 328 non-null    float64\n",
      " 14  CR                                  328 non-null    float64\n",
      " 15  GPM                                 320 non-null    float64\n",
      " 16  NPM                                 326 non-null    float64\n",
      " 17  ROE                                 328 non-null    float64\n",
      " 18  ROA                                 328 non-null    float64\n",
      " 19  IR                                  328 non-null    float64\n",
      " 20  RSL                                 327 non-null    float64\n",
      " 21  Ax1                                 328 non-null    float64\n",
      " 22  Ax2                                 328 non-null    float64\n",
      "dtypes: float64(22), object(1)\n",
      "memory usage: 61.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"Datapooled.csv\")\n",
    "\n",
    "VARS = ['Ganancia bruta', 'Ganancia (pérdida)','Ingresos de actividades ordinarias' , 'Costo de ventas', 'Patrimonio total',\n",
    "     'Total pasivos', 'Total de activos', 'Ganancias acumuladas',  'Pasivos corrientes totales',  'Activos corrientes totales']\n",
    "\n",
    "df_train.rename(columns={'Clasificación Industrial Internacional Uniforme Versión 4 A.C':'Sector'}, inplace=True)\n",
    "\n",
    "df_train = df_train[VARS+[ 'event', 'Sector']]\n",
    "print(df_train[df_train['event']==1].info())\n",
    "df_train['complete-vars'] = complete_vars(df_train) #1 is that have all variables!\n",
    "df_train =  df_train[df_train['complete-vars']==1] #filtering firms that have not financial information \n",
    "print(df_train[df_train['event']==1].info())\n",
    "df_train = ratios(df_train)\n",
    "predictors =[ 'GPM', 'NPM', 'ROE','ROA', 'IR', 'DER', 'RSL', 'CR', 'Ax1', 'Ax2', 'Sector']\n",
    "print(df_train[df_train['event']==1].info())\n",
    "df_train.replace([np.inf,-np.inf], np.nan, inplace=True)\n",
    "df_train.dropna(inplace=True)\n",
    "df_train.drop(columns=['complete-vars'], inplace=True)\n",
    "df_train = df_train[predictors + ['event']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPM\n",
      "NPM\n",
      "ROE\n",
      "ROA\n",
      "IR\n",
      "DER\n",
      "RSL\n",
      "CR\n",
      "Ax1\n",
      "Ax2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sjrp2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1816: UserWarning: p-value may not be accurate for N > 5000.\n",
      "  warnings.warn(\"p-value may not be accurate for N > 5000.\")\n"
     ]
    }
   ],
   "source": [
    "X, y = Xy(df_train, 'event')\n",
    "cat, binaries, nonormal, normal  = breakdown_vars(X)\n",
    "nums = nonormal + normal\n",
    "X = dummies_ohe(X, cat)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state = 666, stratify=y)\n",
    "rus = RandomUnderSampler(random_state=123)\n",
    "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "from preprocessing import standardize_X_test\n",
    "X_test = standardize_X_test(X_train, X_test) # Apply the mean and std of X_test with info from X_train\n",
    "X_train = std_z(nonormal + normal, X_train)\n",
    "\n",
    "vars = [\n",
    "'ROE', 'ROA', \n",
    "'IR', 'DER', \n",
    "'RSL', 'CR', \n",
    "'Sector_C', 'Sector_I',\n",
    "'Sector_K', 'Sector_L', \n",
    "'Sector_O', 'Sector_Q',\n",
    "'Sector_R', 'Sector_U'\n",
    "]\n",
    "\n",
    "\n",
    "X_train, X_test = X_train.loc[:, vars],  X_test.loc[:, vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROE         0\n",
       "ROA         0\n",
       "IR          0\n",
       "DER         0\n",
       "RSL         0\n",
       "CR          0\n",
       "Sector_C    0\n",
       "Sector_I    0\n",
       "Sector_K    0\n",
       "Sector_L    0\n",
       "Sector_O    0\n",
       "Sector_Q    0\n",
       "Sector_R    0\n",
       "Sector_U    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event\n",
       "0.0    254\n",
       "1.0    254\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event\n",
       "0.0    3296\n",
       "1.0      64\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROE         0\n",
       "ROA         0\n",
       "IR          0\n",
       "DER         0\n",
       "RSL         0\n",
       "CR          0\n",
       "Sector_C    0\n",
       "Sector_I    0\n",
       "Sector_K    0\n",
       "Sector_L    0\n",
       "Sector_O    0\n",
       "Sector_Q    0\n",
       "Sector_R    0\n",
       "Sector_U    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROE         0\n",
       "ROA         0\n",
       "IR          0\n",
       "DER         0\n",
       "RSL         0\n",
       "CR          0\n",
       "Sector_C    0\n",
       "Sector_I    0\n",
       "Sector_K    0\n",
       "Sector_L    0\n",
       "Sector_O    0\n",
       "Sector_Q    0\n",
       "Sector_R    0\n",
       "Sector_U    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "def grid_lr(X_train, y_train):\n",
    "    model = LogisticRegression(random_state=666, max_iter=1500)\n",
    "    solvers = ['lbfgs']\n",
    "    penalty = ['l2',None]\n",
    "    c_values = [1000, 100, 10, 1.0, 0.1, 0.01, 0.001,0.0001 , 0.00001 ]\n",
    "    grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv,\n",
    "                           scoring='f1',error_score='raise')\n",
    "    grid_result = grid_search.fit(X_train, y_train)\n",
    "    return  grid_result.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def grid_RandomForest(X_train, y_train):\n",
    "  model = RandomForestClassifier(random_state=666)\n",
    "  n_estimators =  [100, 300, 500, 800]\n",
    "  criterion = ['gini', 'entropy', 'log_loss']\n",
    "  max_depth  =  [None, 5, 10, 30]\n",
    "  min_samples_split =  [2, 5, 10, 15]\n",
    "  min_samples_leaf  =[1, 2, 4, 7]\n",
    "  max_features = ['sqrt', 'log2']\n",
    "\n",
    "\n",
    "  grid = dict(n_estimators = n_estimators, criterion = criterion,  \n",
    "              min_samples_split = min_samples_split,  \n",
    "              max_features=max_features,\n",
    "              max_depth = max_depth,\n",
    "              min_samples_leaf = min_samples_leaf\n",
    "              )\n",
    "  cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "  grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv,\n",
    "                            scoring='f1',error_score='raise')\n",
    "  grid_result = grid_search.fit(X_train, y_train)\n",
    "  return  grid_result.best_estimator_\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Support Vector Machine\n",
    "def grid_SVM(X_train, y_train, performance_metric='f1', resultsGrid=False):\n",
    "    model = SVC(random_state=666)\n",
    "    C = np.linspace(0.000001 , 100, 100)\n",
    "    kernels = ['poly', 'rbf', 'linear']\n",
    "    gamma = ['scale', 'auto']\n",
    "    grid = dict(C = C, kernel = kernels, gamma = gamma)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv,\n",
    "                           scoring=performance_metric,error_score='raise')\n",
    "    grid_result = grid_search.fit(X_train, y_train)\n",
    "    if resultsGrid==True:\n",
    "        return grid_result.cv_results_\n",
    "    else:\n",
    "        return  grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.73      0.84      3296\n",
      "         1.0       0.05      0.80      0.10        64\n",
      "\n",
      "    accuracy                           0.73      3360\n",
      "   macro avg       0.52      0.76      0.47      3360\n",
      "weighted avg       0.98      0.73      0.83      3360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sjrp2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_lr = grid_lr(X_train, y_train)\n",
    "lr_predict = model_lr.predict(X_test)\n",
    "print(classification_report(y_test, lr_predict))\n",
    "lr_table  = pd.DataFrame(classification_report(y_test, lr_predict, output_dict=True)).iloc[:,0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_random_forest  = grid_RandomForest(X_train, y_train)\\nrandom_forest_predict = model_random_forest.predict(X_test)\\nprint(classification_report(y_test, random_forest_predict))\\nrandom_forest_table  = pd.DataFrame(classification_report(y_test,  random_forest_predict, output_dict=True)).iloc[:,0:2]\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model_random_forest  = grid_RandomForest(X_train, y_train)\n",
    "random_forest_predict = model_random_forest.predict(X_test)\n",
    "print(classification_report(y_test, random_forest_predict))\n",
    "random_forest_table  = pd.DataFrame(classification_report(y_test,  random_forest_predict, output_dict=True)).iloc[:,0:2]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.72      0.83      3296\n",
      "         1.0       0.05      0.81      0.10        64\n",
      "\n",
      "    accuracy                           0.72      3360\n",
      "   macro avg       0.52      0.77      0.47      3360\n",
      "weighted avg       0.98      0.72      0.82      3360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_SVM  = grid_SVM(X_train, y_train)\n",
    "SVM_predict = model_SVM.predict(X_test)\n",
    "print(classification_report(y_test, SVM_predict))\n",
    "SVM_table  = pd.DataFrame(classification_report(y_test,  SVM_predict, output_dict=True)).iloc[:,0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def grid_MLP(X_train, y_train):\n",
    "  model = MLPClassifier(random_state=123)\n",
    "  hidden_layer_sizes =  [(5, 5)]\n",
    "  activation = ['logistic']\n",
    "  solver =  ['sgd'] \n",
    "  learning_rate = ['constant', 'invscaling', 'adaptive']\n",
    "  alpha   =  [0.00001, 0.0001, 0.001, 0.01, 1]\n",
    "  learning_rate_init = [0.00001, 0.0001, 0.001, 0.01, 1]\n",
    "  batch_size = [X_train.shape[0]]\n",
    "  momentum = [0.5, 0.8,  0.9 , 1]\n",
    "  max_iter = [500, 700, 1000, 1500, 2000]\n",
    "  grid = dict(hidden_layer_sizes = hidden_layer_sizes,\n",
    "              solver = solver,\n",
    "              alpha = alpha,\n",
    "              max_iter = max_iter,\n",
    "              activation = activation,\n",
    "              batch_size = batch_size,\n",
    "              learning_rate_init = learning_rate_init,\n",
    "              momentum = momentum,\n",
    "              learning_rate = learning_rate)\n",
    "  cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "  grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv,\n",
    "                            scoring='f1',error_score='raise')\n",
    "  grid_result = grid_search.fit(X_train, y_train)\n",
    "  return  grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.75      0.86      3296\n",
      "         1.0       0.06      0.81      0.11        64\n",
      "\n",
      "    accuracy                           0.75      3360\n",
      "   macro avg       0.53      0.78      0.48      3360\n",
      "weighted avg       0.98      0.75      0.84      3360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_mlp  = grid_MLP(X_train, y_train)\n",
    "NN_predict = model_mlp.predict(X_test)\n",
    "print(classification_report(y_test, NN_predict))\n",
    "MLP_table  = pd.DataFrame(classification_report(y_test,  NN_predict, output_dict=True)).iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2d585 th {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2d585\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2d585_level0_col0\" class=\"col_heading level0 col0\" colspan=\"2\">Logistic regression</th>\n",
       "      <th id=\"T_2d585_level0_col2\" class=\"col_heading level0 col2\" colspan=\"2\">Support vector machine</th>\n",
       "      <th id=\"T_2d585_level0_col4\" class=\"col_heading level0 col4\" colspan=\"2\">Backpropagation NN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_2d585_level1_col0\" class=\"col_heading level1 col0\" >No-Default</th>\n",
       "      <th id=\"T_2d585_level1_col1\" class=\"col_heading level1 col1\" >Deafult</th>\n",
       "      <th id=\"T_2d585_level1_col2\" class=\"col_heading level1 col2\" >No-Default</th>\n",
       "      <th id=\"T_2d585_level1_col3\" class=\"col_heading level1 col3\" >Default</th>\n",
       "      <th id=\"T_2d585_level1_col4\" class=\"col_heading level1 col4\" >No-default</th>\n",
       "      <th id=\"T_2d585_level1_col5\" class=\"col_heading level1 col5\" >Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2d585_level0_row0\" class=\"row_heading level0 row0\" >precision</th>\n",
       "      <td id=\"T_2d585_row0_col0\" class=\"data row0 col0\" >0.99</td>\n",
       "      <td id=\"T_2d585_row0_col1\" class=\"data row0 col1\" >0.05</td>\n",
       "      <td id=\"T_2d585_row0_col2\" class=\"data row0 col2\" >0.99</td>\n",
       "      <td id=\"T_2d585_row0_col3\" class=\"data row0 col3\" >0.05</td>\n",
       "      <td id=\"T_2d585_row0_col4\" class=\"data row0 col4\" >1.00</td>\n",
       "      <td id=\"T_2d585_row0_col5\" class=\"data row0 col5\" >0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d585_level0_row1\" class=\"row_heading level0 row1\" >recall</th>\n",
       "      <td id=\"T_2d585_row1_col0\" class=\"data row1 col0\" >0.73</td>\n",
       "      <td id=\"T_2d585_row1_col1\" class=\"data row1 col1\" >0.80</td>\n",
       "      <td id=\"T_2d585_row1_col2\" class=\"data row1 col2\" >0.72</td>\n",
       "      <td id=\"T_2d585_row1_col3\" class=\"data row1 col3\" >0.81</td>\n",
       "      <td id=\"T_2d585_row1_col4\" class=\"data row1 col4\" >0.75</td>\n",
       "      <td id=\"T_2d585_row1_col5\" class=\"data row1 col5\" >0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d585_level0_row2\" class=\"row_heading level0 row2\" >f1-score</th>\n",
       "      <td id=\"T_2d585_row2_col0\" class=\"data row2 col0\" >0.84</td>\n",
       "      <td id=\"T_2d585_row2_col1\" class=\"data row2 col1\" >0.10</td>\n",
       "      <td id=\"T_2d585_row2_col2\" class=\"data row2 col2\" >0.83</td>\n",
       "      <td id=\"T_2d585_row2_col3\" class=\"data row2 col3\" >0.10</td>\n",
       "      <td id=\"T_2d585_row2_col4\" class=\"data row2 col4\" >0.86</td>\n",
       "      <td id=\"T_2d585_row2_col5\" class=\"data row2 col5\" >0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d585_level0_row3\" class=\"row_heading level0 row3\" >support</th>\n",
       "      <td id=\"T_2d585_row3_col0\" class=\"data row3 col0\" >3296.00</td>\n",
       "      <td id=\"T_2d585_row3_col1\" class=\"data row3 col1\" >64.00</td>\n",
       "      <td id=\"T_2d585_row3_col2\" class=\"data row3 col2\" >3296.00</td>\n",
       "      <td id=\"T_2d585_row3_col3\" class=\"data row3 col3\" >64.00</td>\n",
       "      <td id=\"T_2d585_row3_col4\" class=\"data row3 col4\" >3296.00</td>\n",
       "      <td id=\"T_2d585_row3_col5\" class=\"data row3 col5\" >64.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x26a16b62ad0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_tab = pd.concat([lr_table, SVM_table, MLP_table], axis=1)\n",
    "cols_names =  pd.MultiIndex.from_tuples([('Logistic regression','No-Default'),(\"Logistic regression\",'Deafult'),\n",
    "              (\"Support vector machine\",'No-Default'),('Support vector machine','Default'),\n",
    "              ('Backpropagation NN', 'No-default'), ('Backpropagation NN', 'Default'),])\n",
    "models_tab.columns  = cols_names\n",
    "models_tab = models_tab.style.set_table_styles([\n",
    "   {'selector': 'th','props': [('text-align', 'center')]}]).format(precision=2)\n",
    "models_tab.to_latex(\"benchmark-models.tex\")\n",
    "models_tab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
