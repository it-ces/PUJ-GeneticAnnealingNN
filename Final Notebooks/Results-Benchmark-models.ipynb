{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/it-ces/PUJ-GeneticAnnealingNN/blob/main/Final%20Notebooks/Results-Benchmark-models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/it-ces/PUJ-GeneticAnnealingNN.git"
      ],
      "metadata": {
        "id": "hz2GueDjp3j5",
        "outputId": "fe4f407b-6ec7-49aa-efde-b521e7f0268e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PUJ-GeneticAnnealingNN'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 46 (delta 9), reused 43 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (46/46), 3.65 MiB | 4.93 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd PUJ-GeneticAnnealingNN/project"
      ],
      "metadata": {
        "id": "47i6Syh8qAaY",
        "outputId": "59bba9c5-c815-412b-84f9-fc260403eb8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/epa/PUJ-GeneticAnnealingNN/project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Zdnwhsjop0YJ"
      },
      "outputs": [],
      "source": [
        "# Benchmark models\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from preprocessing import complete_vars\n",
        "from preprocessing import ratios\n",
        "from preprocessing import breakdown_vars\n",
        "from preprocessing import dummies_ohe\n",
        "from preprocessing import Xy\n",
        "from preprocessing import std_z\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3FIo-ttp0YM"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"Datapooled.csv\")\n",
        "\n",
        "VARS = ['Ganancia bruta', 'Ganancia (pérdida)','Ingresos de actividades ordinarias' , 'Costo de ventas', 'Patrimonio total',\n",
        "     'Total pasivos', 'Total de activos', 'Ganancias acumuladas',  'Pasivos corrientes totales',  'Activos corrientes totales']\n",
        "\n",
        "df_train.rename(columns={'Clasificación Industrial Internacional Uniforme Versión 4 A.C':'Sector'}, inplace=True)\n",
        "\n",
        "df_train = df_train[VARS+[ 'event', 'Sector']]\n",
        "print(df_train[df_train['event']==1].info())\n",
        "df_train['complete-vars'] = complete_vars(df_train) #1 is that have all variables!\n",
        "df_train =  df_train[df_train['complete-vars']==1] #filtering firms that have not financial information\n",
        "print(df_train[df_train['event']==1].info())\n",
        "df_train = ratios(df_train)\n",
        "predictors =[ 'GPM', 'NPM', 'ROE','ROA', 'IR', 'DER', 'RSL', 'CR', 'Ax1', 'Ax2', 'Sector']\n",
        "print(df_train[df_train['event']==1].info())\n",
        "df_train.replace([np.inf,-np.inf], np.nan, inplace=True)\n",
        "df_train.dropna(inplace=True)\n",
        "df_train.drop(columns=['complete-vars'], inplace=True)\n",
        "df_train = df_train[predictors + ['event']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUXeJDqAp0YP"
      },
      "outputs": [],
      "source": [
        "X, y = Xy(df_train, 'event')\n",
        "cat, binaries, nonormal, normal  = breakdown_vars(X)\n",
        "nums = nonormal + normal\n",
        "X = dummies_ohe(X, cat)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state = 666, stratify=y)\n",
        "rus = RandomUnderSampler(random_state=123)\n",
        "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
        "from preprocessing import standardize_X_test\n",
        "X_test = standardize_X_test(X_train, X_test) # Apply the mean and std of X_test with info from X_train\n",
        "X_train = std_z(nonormal + normal, X_train)\n",
        "\n",
        "vars = [\n",
        "'ROE', 'ROA',\n",
        "'IR', 'DER',\n",
        "'RSL', 'CR',\n",
        "'Sector_C', 'Sector_I',\n",
        "'Sector_K', 'Sector_L',\n",
        "'Sector_O', 'Sector_Q',\n",
        "'Sector_R', 'Sector_U'\n",
        "]\n",
        "\n",
        "\n",
        "X_train, X_test = X_train.loc[:, vars],  X_test.loc[:, vars]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txDxv1NHp0YQ"
      },
      "outputs": [],
      "source": [
        "X_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SGZeUMap0YQ"
      },
      "outputs": [],
      "source": [
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1de8aalNp0YR"
      },
      "outputs": [],
      "source": [
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwWpXxSrp0YR"
      },
      "outputs": [],
      "source": [
        "X_train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ51cakop0YR"
      },
      "outputs": [],
      "source": [
        "X_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VR9D3IHlp0YS"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "def grid_lr(X_train, y_train):\n",
        "    model = LogisticRegression(random_state=666, max_iter=1500)\n",
        "    solvers = ['lbfgs']\n",
        "    penalty = ['l2',None]\n",
        "    c_values = [1000, 100, 10, 1.0, 0.1, 0.01, 0.001,0.0001 , 0.00001 ]\n",
        "    grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv,\n",
        "                           scoring='f1',error_score='raise')\n",
        "    grid_result = grid_search.fit(X_train, y_train)\n",
        "    return  grid_result.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def grid_RandomForest(X_train, y_train):\n",
        "  model = RandomForestClassifier(random_state=666)\n",
        "  n_estimators =  [100, 300, 500, 800]\n",
        "  criterion = ['gini', 'entropy', 'log_loss']\n",
        "  max_depth  =  [None, 5, 10, 30]\n",
        "  min_samples_split =  [2, 5, 10, 15]\n",
        "  min_samples_leaf  =[1, 2, 4, 7]\n",
        "  max_features = ['sqrt', 'log2']\n",
        "\n",
        "\n",
        "  grid = dict(n_estimators = n_estimators, criterion = criterion,\n",
        "              min_samples_split = min_samples_split,\n",
        "              max_features=max_features,\n",
        "              max_depth = max_depth,\n",
        "              min_samples_leaf = min_samples_leaf\n",
        "              )\n",
        "  cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
        "  grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv,\n",
        "                            scoring='f1',error_score='raise')\n",
        "  grid_result = grid_search.fit(X_train, y_train)\n",
        "  return  grid_result.best_estimator_\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# Support Vector Machine\n",
        "def grid_SVM(X_train, y_train, performance_metric='f1', resultsGrid=False):\n",
        "    model = SVC(random_state=666)\n",
        "    C = np.linspace(0.000001 , 100, 100)\n",
        "    kernels = ['poly', 'rbf', 'linear']\n",
        "    gamma = ['scale', 'auto']\n",
        "    grid = dict(C = C, kernel = kernels, gamma = gamma)\n",
        "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv,\n",
        "                           scoring=performance_metric,error_score='raise')\n",
        "    grid_result = grid_search.fit(X_train, y_train)\n",
        "    if resultsGrid==True:\n",
        "        return grid_result.cv_results_\n",
        "    else:\n",
        "        return  grid_result.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAD2yc9Xp0YT"
      },
      "outputs": [],
      "source": [
        "model_lr = grid_lr(X_train, y_train)\n",
        "lr_predict = model_lr.predict(X_test)\n",
        "print(classification_report(y_test, lr_predict))\n",
        "lr_table  = pd.DataFrame(classification_report(y_test, lr_predict, output_dict=True)).iloc[:,0:2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-q1oosLp0YT"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "model_random_forest  = grid_RandomForest(X_train, y_train)\n",
        "random_forest_predict = model_random_forest.predict(X_test)\n",
        "print(classification_report(y_test, random_forest_predict))\n",
        "random_forest_table  = pd.DataFrame(classification_report(y_test,  random_forest_predict, output_dict=True)).iloc[:,0:2]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qD4dwmvlp0YU"
      },
      "outputs": [],
      "source": [
        "model_SVM  = grid_SVM(X_train, y_train)\n",
        "SVM_predict = model_SVM.predict(X_test)\n",
        "print(classification_report(y_test, SVM_predict))\n",
        "SVM_table  = pd.DataFrame(classification_report(y_test,  SVM_predict, output_dict=True)).iloc[:,0:2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6chcMekYp0YU"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "def grid_MLP(X_train, y_train):\n",
        "  model = MLPClassifier(random_state=123)\n",
        "  hidden_layer_sizes =  [(5, 5)]\n",
        "  activation = ['logistic']\n",
        "  solver =  ['sgd']\n",
        "  learning_rate = ['constant', 'invscaling', 'adaptive']\n",
        "  alpha   =  [0.00001, 0.0001, 0.001, 0.01, 1]\n",
        "  learning_rate_init = [0.00001, 0.0001, 0.001, 0.01, 1]\n",
        "  batch_size = [X_train.shape[0]]\n",
        "  momentum = [0.5, 0.8,  0.9 , 1]\n",
        "  max_iter = [500, 700, 1000, 1500, 2000]\n",
        "  grid = dict(hidden_layer_sizes = hidden_layer_sizes,\n",
        "              solver = solver,\n",
        "              alpha = alpha,\n",
        "              max_iter = max_iter,\n",
        "              activation = activation,\n",
        "              batch_size = batch_size,\n",
        "              learning_rate_init = learning_rate_init,\n",
        "              momentum = momentum,\n",
        "              learning_rate = learning_rate)\n",
        "  cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
        "  grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv,\n",
        "                            scoring='f1',error_score='raise')\n",
        "  grid_result = grid_search.fit(X_train, y_train)\n",
        "  return  grid_result.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYoyi1_0p0YV"
      },
      "outputs": [],
      "source": [
        "model_mlp  = grid_MLP(X_train, y_train)\n",
        "NN_predict = model_mlp.predict(X_test)\n",
        "print(classification_report(y_test, NN_predict))\n",
        "MLP_table  = pd.DataFrame(classification_report(y_test,  NN_predict, output_dict=True)).iloc[:,0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hrLzLTPp0YV"
      },
      "outputs": [],
      "source": [
        "models_tab = pd.concat([lr_table, SVM_table, MLP_table], axis=1)\n",
        "cols_names =  pd.MultiIndex.from_tuples([('Logistic regression','No-Default'),(\"Logistic regression\",'Deafult'),\n",
        "              (\"Support vector machine\",'No-Default'),('Support vector machine','Default'),\n",
        "              ('Backpropagation NN', 'No-default'), ('Backpropagation NN', 'Default'),])\n",
        "models_tab.columns  = cols_names\n",
        "models_tab = models_tab.style.set_table_styles([\n",
        "   {'selector': 'th','props': [('text-align', 'center')]}]).format(precision=2)\n",
        "models_tab.to_latex(\"benchmark-models.tex\")\n",
        "models_tab"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}